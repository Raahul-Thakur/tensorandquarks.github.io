<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home | Tensors & Quarks</title>
    <link rel="stylesheet" href="/assets/style.css" />

    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }
      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Home | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Home" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://www.tensorsandquarks.space/" />
<meta property="og:url" content="https://www.tensorsandquarks.space/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<link rel="next" href="https://www.tensorsandquarks.space/page2" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Home","name":"Tensors &amp; Quarks","url":"https://www.tensorsandquarks.space/"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">
            <a href="/"><span>Tensors & Quarks</span></a>
          </h1>
        </div>
        <nav class="nav" aria-label="Primary navigation">
          <a class="nav-link" href="/">Home</a>
          <a class="nav-link" href="/about.html">About</a>
          <button class="dark-toggle" type="button" onclick="toggleDarkMode()" aria-label="Toggle dark mode">üåì</button>
        </nav>
      </div>
    </header>

    <main id="main-content" class="container">
      <div class="hero">
        <p class="hero-kicker">Physics ‚Ä¢ Machine Learning ‚Ä¢ Curiosity</p>
        <h1>Welcome to <span class="gradient-text">Tensors &amp; Quarks</span></h1>
        <p>Exploring the cosmos of <strong>physics</strong> and the depths of <strong>machine learning</strong> with hands-on experiments, notes, and essays.</p>
        <div class="hero-actions">
          <a href="#latest-posts">Read the latest insights</a>
          <a href="/about.html">Meet the author</a>
        </div>
      </div>

      <div class="tag-filter">
        <span class="tag-filter-label">Explore topics</span>
        <div class="tag-filter-tags">
          <a class="tag-chip" href="/tags/ml/">ML</a>
          <a class="tag-chip" href="/tags/astrophysics/">Astrophysics</a>
          <a class="tag-chip" href="/tags/misc/">Misc</a>
        </div>
      </div>

      <h2 id="latest-posts">Latest Posts</h2>
      <ul class="post-list">
        
          <li class="post-card">
            <h3><a href="/2025/10/31/hierarchical.html"></a></h3>
            <p class="post-meta">
              October 31, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="when-ai-stopped-talking-and-started-thinking">When AI Stopped Talking and Started Thinking</h1>

<p>Reasoning ‚Äî the holy grail of AI ‚Äî has long been the gap between memorization and actual understanding. Most modern large language models (LLMs) simulate reasoning through <strong>Chain-of-Thought (CoT)</strong> prompting, a clever trick where the model narrates its logic step-by-step. Unfortunately, this is more like a magician describing the illusion rather than truly performing it. CoT depends on verbose linguistic scaffolding, brittle decomposition, and mountains of training data. If you drop one logical domino, the entire thought process collapses.</p>

</p>
            <a href="/2025/10/31/hierarchical.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/10/24/alphaevolve.html"></a></h3>
            <p class="post-meta">
              October 24, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="how-alphaevolve-found-what-mathematicians-missed-for-56-years">How AlphaEvolve Found What Mathematicians Missed for 56 Years</h1>

<h2 id="abstract--overview">Abstract / Overview</h2>

<p>AlphaEvolve, developed by Google DeepMind, is an evolutionary coding agent designed to autonomously discover and optimize algorithms. Unlike single-model LLM setups, it orchestrates a pipeline of large language models that iteratively modify, test, and refine code. Each iteration is evaluated automatically, forming a feedback loop that resembles biological evolution: mutation, evaluation, and selection. This self-improving process has yielded breakthroughs across mathematics, engineering, and AI infrastructure. Notably, AlphaEvolve discovered the first improvement in matrix-multiplication algorithms in <strong>56 years</strong>, reducing the number of scalar multiplications for 4√ó4 complex matrices from 49 to 48.</p>

</p>
            <a href="/2025/10/24/alphaevolve.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/10/16/seedprover.html"></a></h3>
            <p class="post-meta">
              October 16, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-intuition-to-axiom-the-story-of-an-ai-that-learned-to-prove">From Intuition to Axiom: The Story of an AI That Learned to Prove</h1>

<p>Mathematics has always been the ultimate test of structured reasoning. While large language models (LLMs) like GPT-4 or DeepSeek can reason through complex text, they often stumble where human mathematicians shine ‚Äî constructing airtight, verifiable proofs.</p>

</p>
            <a href="/2025/10/16/seedprover.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/10/10/subliminal-learning.html"></a></h3>
            <p class="post-meta">
              October 10, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="hidden-whispers-how-ai-models-secretly-pass-on-their-traits">Hidden Whispers: How AI Models Secretly Pass On Their Traits</h1>

<p><em>What if your AI model could inherit its parent‚Äôs quirks ‚Äî even through meaningless data? Anthropic‚Äôs 2025 paper ‚ÄúSubliminal Learning‚Äù reveals how that happens ‚Äî and why it changes everything about AI safety.</em></p>

</p>
            <a href="/2025/10/10/subliminal-learning.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/10/03/godel-test.html"></a></h3>
            <p class="post-meta">
              October 3, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-prompts-to-proofs-can-chatgpt-pass-the-g√∂del-test">From Prompts to Proofs: Can ChatGPT Pass the G√∂del Test?</h1>

<p>ChatGPT has become a part of our daily lives in ways we could not have imagined just a few years ago. From writing emails and polishing presentations to generating working code for side projects, it has become a universal assistant. But beyond these everyday tasks, what are the true capabilities of models like ChatGPT and its successors? Can they go beyond imitating human output and actually contribute to fields that demand creativity and rigor‚Äîlike mathematics? This question is at the heart of a recent research paper, <em>G√∂del Test: Can Large Language Models Solve Easy Conjectures?</em> published just a week ago. The paper does not ask whether large language models can memorize or recall results, but whether they can engage in something far more ambitious: creating new mathematics. In this blog, I want to walk through what the paper does, why it matters, and what it means for the future of artificial intelligence and mathematical discovery.</p>

</p>
            <a href="/2025/10/03/godel-test.html" class="read-more">Read more ‚Üí</a>
          </li>
        
      </ul>

      <div class="pagination">
        

        <span>Page 1 of 9</span>

        
          <a href="/page2">Older Posts &rarr;</a>
        
      </div>
    </main>

    <footer class="site-footer">
      <div class="container">
        <p>¬© 2025 Rahul Thakur ‚Ä¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
