<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home | Tensors & Quarks</title>
    <link rel="stylesheet" href="/tensorandquarks.github.io/assets/style.css" />

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }
      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Home | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Home" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://raahul-thakur.github.io/tensorandquarks.github.io/" />
<meta property="og:url" content="https://raahul-thakur.github.io/tensorandquarks.github.io/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<link rel="next" href="https://raahul-thakur.github.io/tensorandquarks.github.io/page2" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Home","name":"Tensors &amp; Quarks","url":"https://raahul-thakur.github.io/tensorandquarks.github.io/"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/tensorandquarks.github.io/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/tensorandquarks.github.io/">Home</a>
          <a href="/tensorandquarks.github.io/about.html">About</a>
          <button onclick="toggleDarkMode()">🌓</button>
        </nav>
      </div>
    </header>

    <main class="container">
      <div class="hero">
        <h1>Welcome to Tensors & Quarks</h1>
        <p>Exploring the cosmos of <strong>Physics</strong> & the depths of <strong>Machine Learning</strong>.</p>
      </div>

      <div class="tag-filter">
        <strong>Filter by Tag:</strong>
        <a href="/tensorandquarks.github.io/tags/ml/">ML</a> |
        <a href="/tensorandquarks.github.io/tags/astrophysics/">Astrophysics</a> |
        <a href="/tensorandquarks.github.io/tags/misc/">Misc</a>
      </div>

      <h2>Latest Posts</h2>
      <ul class="post-list">
        
          <li class="post-card">
            <h3><a href="/tensorandquarks.github.io/2025/04/03/llm-blackbox-pt2.html"></a></h3>
            <p class="post-meta">
              April 3, 2025
              
                — Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-circuits-to-cognition-following-the-thoughts-of-claude-35">From Circuits to Cognition: Following the Thoughts of Claude 3.5</h1>
<h2 id="decoding-anthropics-next-step-in-understanding-language-models">Decoding Anthropic’s Next Step in Understanding Language Models</h2>

<p>In my previous post, we explored <em>“On the Biology of a Large Language Model”</em>, Anthropic’s groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using <strong>attribution graphs</strong>. These graphs offered a glimpse into the hidden architecture of reasoning — showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates.</p>

<p>But what if we could go a step further?</p>

<p>What if, instead of just identifying the components responsible for thought, we could <strong>trace a single idea as it unfolds inside the model — moment by moment, token by token</strong>?</p>

<p>That’s exactly what Anthropic attempts in their new article: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model"><em>“Tracing the Thoughts of a Language Model”</em></a>. It builds directly on the foundation of attribution graphs and pushes us deeper into the mind of a transformer — not to observe its structure, but to follow its <em>thinking</em>.</p>

<hr />

<h2 id="thought-as-a-path-not-just-a-spark">Thought as a Path, Not Just a Spark</h2>

<p>The original paper dissected how circuits activate to solve sub-tasks — arithmetic, rhyme planning, multilingual parsing. In this new work, Anthropic tracks what happens <strong>after</strong> a feature activates. Where does it go? What does it influence? What follows?</p>

<p>Imagine prompting Claude with a sentence like:</p>

<blockquote>
  <p>“Describe how biology influences philosophy.”</p>
</blockquote>

<p>This prompt doesn’t just activate features for “biology” — it sets off a chain reaction. The “biology” feature interacts with others: “evolution,” “Darwin,” “ethics,” “reasoning,” and eventually, “philosophy.” Using <strong>token-by-token attribution graphs</strong>, Anthropic visualizes how one thought <strong>cascades</strong> through the network.</p>

<p>These “thought chains” aren’t linear. Some tokens reinforce earlier ideas. Others suppress or redirect them. Concepts may disappear temporarily, only to resurface later with stronger activation — a kind of <strong>working memory</strong>. This dynamic flow is what Anthropic now calls <em>thought tracing</em>.</p>

<hr />

<h2 id="a-model-that-strategizes-yes--and-we-can-watch-it">A Model That Strategizes? Yes — and We Can Watch It</h2>

<p>Just like in the earlier poetry example, Claude doesn’t merely complete sentences — it <strong>plans</strong>. In the new study, the researchers show how the model can begin forming a mental structure even before certain tokens are generated.</p>

<p>For instance, features related to “ethics” might activate <strong>before</strong> the word appears, because the model anticipates its relevance to “biology + philosophy.” Attribution graphs reveal how these anticipations manifest as <strong>early activations</strong> of supporting features, which then guide downstream generation.</p>

<p>This is a profound shift in how we think about LLMs: not as reactionary next-word predictors, but as <strong>goal-conditioned planners</strong>. And now, we can trace those goals step-by-step.</p>

<hr />

<h2 id="a-second-brain-inside-claude">A Second Brain Inside Claude</h2>

<p>So what exactly is being revealed here?</p>

<p>The new article essentially treats the LLM as a <strong>second brain</strong> — not just in metaphor, but in methodology. Where the original paper mapped the “organs” (modular circuits), this one traces <strong>synaptic firing</strong> across those modules in real time.</p>

<p>It’s a neuroscience-inspired look at AI, and it suggests that Claude builds meaning not by memorizing facts, but by <strong>composing them dynamically</strong> across internal systems.</p>

<p>In this way, “thought” becomes not a static activation, but a <strong>trajectory</strong> — a living path formed and updated as the model processes the prompt.</p>

<hr />

<h2 id="prompting-with-precision-the-future-of-language-engineering">Prompting with Precision: The Future of Language Engineering</h2>

<p>One practical implication? <strong>Prompt engineering could evolve into thought-path design.</strong></p>

<p>If we understand which phrases activate which paths, we could design prompts that:</p>
<ul>
  <li>Strengthen the recall of helpful circuits</li>
  <li>Suppress misleading associations</li>
  <li>Steer reasoning toward desired conclusions</li>
</ul>

<p>It’s no longer guesswork — it’s <strong>cognitive scaffolding</strong>.</p>

<p>This insight also holds promise for safety research. Tracing how harmful thoughts arise — and from which token or feature — gives us a tool to <strong>preempt hallucinations and jailbreaks</strong> with surgical precision.</p>

<hr />

<h2 id="a-new-lens-for-interpretability">A New Lens for Interpretability</h2>

<p>In many ways, this new article doesn’t replace the original paper — it <strong>completes it</strong>.</p>

<table>
  <thead>
    <tr>
      <th><strong>Biology of a Language Model</strong></th>
      <th><strong>Tracing the Thoughts</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Maps internal features and circuits</td>
      <td>Traces real-time activation of those features</td>
    </tr>
    <tr>
      <td>Shows where reasoning lives</td>
      <td>Shows how reasoning moves</td>
    </tr>
    <tr>
      <td>Highlights modularity</td>
      <td>Highlights dynamics</td>
    </tr>
    <tr>
      <td>Inspired by anatomy</td>
      <td>Inspired by cognition</td>
    </tr>
  </tbody>
</table>

<p>Together, they shift the view of LLMs from static black boxes to <strong>living systems</strong> — ones that can be studied, debugged, and potentially aligned more deeply with human values.</p>

<hr />

<h2 id="final-thoughts">Final Thoughts</h2>

<p>There’s something quietly radical about this line of research.</p>

<p>Not long ago, we believed language models were statistical parrots. Then we found circuits. Now we see thoughts. It’s a reminder that <strong>intelligence isn’t magic — it’s mechanics</strong>. And with the right tools, even the most complex digital minds can be understood.</p>

<p>Anthropic’s new work marks a step toward <em>transparent cognition</em> — not just knowing <em>what</em> a model says, but <em>why</em> it thinks it.</p>

<p>And once we understand that… maybe we’re not so far from building models that can explain themselves — to us, and perhaps, even to each other.</p>

<hr />

<p><em>Want to see how a single thought spreads across 70 transformer layers? Explore Anthropic’s full article here: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Tracing the Thoughts of a Language Model</a>.</em></p>
</p>
            <a href="/tensorandquarks.github.io/2025/04/03/llm-blackbox-pt2.html" class="read-more">Read more →</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html"></a></h3>
            <p class="post-meta">
              March 28, 2025
              
                — Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-black-box-to-blueprint-tracing-the-logic-of-claude-35">From Black Box to Blueprint: Tracing the Logic of Claude 3.5</h1>
<h2 id="exploring-the-hidden-anatomy-of-a-language-model">Exploring the Hidden Anatomy of a Language Model</h2>

<p>In the age of large language models, capability often outpaces comprehension. Models like Claude 3.5 can write poetry, solve logic puzzles, and navigate multilingual queries — but we still don’t fully understand <em>how</em>. Beneath their fluent outputs lies a vast architecture of layers, weights, and attention heads that, until recently, remained largely inscrutable.</p>

</p>
            <a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html" class="read-more">Read more →</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/tensorandquarks.github.io/2025/03/20/inception.html"></a></h3>
            <p class="post-meta">
              March 20, 2025
              
                — Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="the-deepening-layers-of-inception-a-journey-through-cnn-time">The Deepening Layers of Inception: A Journey Through CNN Time</h1>

<p>The story of the Inception architecture is one of ingenuity, iteration, and elegance in the field of deep learning. At a time when researchers were obsessed with increasing the depth and complexity of convolutional neural networks (CNNs) to improve accuracy on large-scale visual tasks, Google’s research team asked a different question: How can we go deeper without paying the full computational price? The answer was Inception—a family of architectures that offered a bold new design paradigm, prioritizing both <strong>computational efficiency and representational power</strong>. From <strong>Inception v1 (GoogLeNet)</strong> to <strong>Inception-ResNet v2</strong>, each version brought transformative ideas that would ripple throughout the deep learning community. This post unpacks the entire journey, layer by layer, innovation by innovation.</p>

</p>
            <a href="/tensorandquarks.github.io/2025/03/20/inception.html" class="read-more">Read more →</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/tensorandquarks.github.io/2025/03/13/imagenet.html"></a></h3>
            <p class="post-meta">
              March 13, 2025
              
                — Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="how-imagenet-taught-machines-to-see">How ImageNet Taught Machines to See</h1>

<h2 id="the-vision-behind-the-dataset">The Vision Behind the Dataset</h2>

<p>In the early 2000s, artificial intelligence was still stumbling in the dark when it came to understanding images. Researchers had built systems that could play chess or perform basic language tasks, but when it came to something a toddler could do—like identifying a cat in a photo—machines struggled. There was a glaring gap between the potential of machine learning and its real-world applications in vision.</p>

</p>
            <a href="/tensorandquarks.github.io/2025/03/13/imagenet.html" class="read-more">Read more →</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html"></a></h3>
            <p class="post-meta">
              March 6, 2025
              
                — Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="the-random-illusion-why-adversarial-defenses-arent-as-robust-as-they-seem">The Random Illusion: Why Adversarial Defenses Aren’t as Robust as They Seem</h1>

<p>The field of adversarial machine learning is built on a paradox: models that perform impressively on natural data can be shockingly vulnerable to small, human-imperceptible perturbations. These adversarial examples expose a fragility in deep networks that could have serious consequences in security-critical domains like autonomous driving, medical imaging, or biometric authentication. Naturally, defenses against these attacks have been the subject of intense research. Among them, a seemingly simple strategy has gained popularity: <strong>random transformations</strong>. By applying random, often non-differentiable perturbations to input images—such as resizing, padding, cropping, JPEG compression, or color quantization—these methods hope to break the adversary’s control over the gradients that guide attacks. At first glance, it seems effective. Robust accuracy increases. Attacks fail. But is this robustness genuine?</p>

</p>
            <a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html" class="read-more">Read more →</a>
          </li>
        
      </ul>

      <div class="pagination">
        

        <span>Page 1 of 6</span>

        
          <a href="/tensorandquarks.github.io/page2">Older Posts &rarr;</a>
        
      </div>
    </main>

    <footer class="site-footer">
      <div class="container">
        <p>© 2025 Rahul Thakur • Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
