<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Posts tagged ML | Tensors & Quarks</title>
    <link rel="stylesheet" href="/tensorandquarks.github.io/assets/style.css" />

    <!-- üåì Dark Mode Script -->
    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }

      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- ‚úÖ MathJax Support -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Posts tagged ML | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Posts tagged ML" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/" />
<meta property="og:url" content="https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Posts tagged ML" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Posts tagged ML","url":"https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/tensorandquarks.github.io/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/tensorandquarks.github.io/">Home</a>
          <a href="/tensorandquarks.github.io/about.html">About</a>
          <button onclick="toggleDarkMode()">üåì</button>
        </nav>
      </div>
    </header>

    <main class="container">
      <h1>Posts tagged ML</h1>

<ul class="post-list">
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/04/03/llm-blackbox-pt2.html"></a></h2>
        <p class="post-meta">
          April 3, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-circuits-to-cognition-following-the-thoughts-of-claude-35">From Circuits to Cognition: Following the Thoughts of Claude 3.5</h1>
<h2 id="decoding-anthropics-next-step-in-understanding-language-models">Decoding Anthropic‚Äôs Next Step in Understanding Language Models</h2>

<p>In my previous post, we explored <em>‚ÄúOn the Biology of a Large Language Model‚Äù</em>, Anthropic‚Äôs groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using <strong>attribution graphs</strong>. These graphs offered a glimpse into the hidden architecture of reasoning ‚Äî showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates.</p>

<p>But what if we could go a step further?</p>

<p>What if, instead of just identifying the components responsible for thought, we could <strong>trace a single idea as it unfolds inside the model ‚Äî moment by moment, token by token</strong>?</p>

<p>That‚Äôs exactly what Anthropic attempts in their new article: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model"><em>‚ÄúTracing the Thoughts of a Language Model‚Äù</em></a>. It builds directly on the foundation of attribution graphs and pushes us deeper into the mind of a transformer ‚Äî not to observe its structure, but to follow its <em>thinking</em>.</p>

<hr />

<h2 id="thought-as-a-path-not-just-a-spark">Thought as a Path, Not Just a Spark</h2>

<p>The original paper dissected how circuits activate to solve sub-tasks ‚Äî arithmetic, rhyme planning, multilingual parsing. In this new work, Anthropic tracks what happens <strong>after</strong> a feature activates. Where does it go? What does it influence? What follows?</p>

<p>Imagine prompting Claude with a sentence like:</p>

<blockquote>
  <p>‚ÄúDescribe how biology influences philosophy.‚Äù</p>
</blockquote>

<p>This prompt doesn‚Äôt just activate features for ‚Äúbiology‚Äù ‚Äî it sets off a chain reaction. The ‚Äúbiology‚Äù feature interacts with others: ‚Äúevolution,‚Äù ‚ÄúDarwin,‚Äù ‚Äúethics,‚Äù ‚Äúreasoning,‚Äù and eventually, ‚Äúphilosophy.‚Äù Using <strong>token-by-token attribution graphs</strong>, Anthropic visualizes how one thought <strong>cascades</strong> through the network.</p>

<p>These ‚Äúthought chains‚Äù aren‚Äôt linear. Some tokens reinforce earlier ideas. Others suppress or redirect them. Concepts may disappear temporarily, only to resurface later with stronger activation ‚Äî a kind of <strong>working memory</strong>. This dynamic flow is what Anthropic now calls <em>thought tracing</em>.</p>

<hr />

<h2 id="a-model-that-strategizes-yes--and-we-can-watch-it">A Model That Strategizes? Yes ‚Äî and We Can Watch It</h2>

<p>Just like in the earlier poetry example, Claude doesn‚Äôt merely complete sentences ‚Äî it <strong>plans</strong>. In the new study, the researchers show how the model can begin forming a mental structure even before certain tokens are generated.</p>

<p>For instance, features related to ‚Äúethics‚Äù might activate <strong>before</strong> the word appears, because the model anticipates its relevance to ‚Äúbiology + philosophy.‚Äù Attribution graphs reveal how these anticipations manifest as <strong>early activations</strong> of supporting features, which then guide downstream generation.</p>

<p>This is a profound shift in how we think about LLMs: not as reactionary next-word predictors, but as <strong>goal-conditioned planners</strong>. And now, we can trace those goals step-by-step.</p>

<hr />

<h2 id="a-second-brain-inside-claude">A Second Brain Inside Claude</h2>

<p>So what exactly is being revealed here?</p>

<p>The new article essentially treats the LLM as a <strong>second brain</strong> ‚Äî not just in metaphor, but in methodology. Where the original paper mapped the ‚Äúorgans‚Äù (modular circuits), this one traces <strong>synaptic firing</strong> across those modules in real time.</p>

<p>It‚Äôs a neuroscience-inspired look at AI, and it suggests that Claude builds meaning not by memorizing facts, but by <strong>composing them dynamically</strong> across internal systems.</p>

<p>In this way, ‚Äúthought‚Äù becomes not a static activation, but a <strong>trajectory</strong> ‚Äî a living path formed and updated as the model processes the prompt.</p>

<hr />

<h2 id="prompting-with-precision-the-future-of-language-engineering">Prompting with Precision: The Future of Language Engineering</h2>

<p>One practical implication? <strong>Prompt engineering could evolve into thought-path design.</strong></p>

<p>If we understand which phrases activate which paths, we could design prompts that:</p>
<ul>
  <li>Strengthen the recall of helpful circuits</li>
  <li>Suppress misleading associations</li>
  <li>Steer reasoning toward desired conclusions</li>
</ul>

<p>It‚Äôs no longer guesswork ‚Äî it‚Äôs <strong>cognitive scaffolding</strong>.</p>

<p>This insight also holds promise for safety research. Tracing how harmful thoughts arise ‚Äî and from which token or feature ‚Äî gives us a tool to <strong>preempt hallucinations and jailbreaks</strong> with surgical precision.</p>

<hr />

<h2 id="a-new-lens-for-interpretability">A New Lens for Interpretability</h2>

<p>In many ways, this new article doesn‚Äôt replace the original paper ‚Äî it <strong>completes it</strong>.</p>

<table>
  <thead>
    <tr>
      <th><strong>Biology of a Language Model</strong></th>
      <th><strong>Tracing the Thoughts</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Maps internal features and circuits</td>
      <td>Traces real-time activation of those features</td>
    </tr>
    <tr>
      <td>Shows where reasoning lives</td>
      <td>Shows how reasoning moves</td>
    </tr>
    <tr>
      <td>Highlights modularity</td>
      <td>Highlights dynamics</td>
    </tr>
    <tr>
      <td>Inspired by anatomy</td>
      <td>Inspired by cognition</td>
    </tr>
  </tbody>
</table>

<p>Together, they shift the view of LLMs from static black boxes to <strong>living systems</strong> ‚Äî ones that can be studied, debugged, and potentially aligned more deeply with human values.</p>

<hr />

<h2 id="final-thoughts">Final Thoughts</h2>

<p>There‚Äôs something quietly radical about this line of research.</p>

<p>Not long ago, we believed language models were statistical parrots. Then we found circuits. Now we see thoughts. It‚Äôs a reminder that <strong>intelligence isn‚Äôt magic ‚Äî it‚Äôs mechanics</strong>. And with the right tools, even the most complex digital minds can be understood.</p>

<p>Anthropic‚Äôs new work marks a step toward <em>transparent cognition</em> ‚Äî not just knowing <em>what</em> a model says, but <em>why</em> it thinks it.</p>

<p>And once we understand that‚Ä¶ maybe we‚Äôre not so far from building models that can explain themselves ‚Äî to us, and perhaps, even to each other.</p>

<hr />

<p><em>Want to see how a single thought spreads across 70 transformer layers? Explore Anthropic‚Äôs full article here: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Tracing the Thoughts of a Language Model</a>.</em></p>
</p>
        <a href="/tensorandquarks.github.io/2025/04/03/llm-blackbox-pt2.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html"></a></h2>
        <p class="post-meta">
          March 28, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-black-box-to-blueprint-tracing-the-logic-of-claude-35">From Black Box to Blueprint: Tracing the Logic of Claude 3.5</h1>
<h2 id="exploring-the-hidden-anatomy-of-a-language-model">Exploring the Hidden Anatomy of a Language Model</h2>

<p>In the age of large language models, capability often outpaces comprehension. Models like Claude 3.5 can write poetry, solve logic puzzles, and navigate multilingual queries ‚Äî but we still don‚Äôt fully understand <em>how</em>. Beneath their fluent outputs lies a vast architecture of layers, weights, and attention heads that, until recently, remained largely inscrutable.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/20/inception.html"></a></h2>
        <p class="post-meta">
          March 20, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-deepening-layers-of-inception-a-journey-through-cnn-time">The Deepening Layers of Inception: A Journey Through CNN Time</h1>

<p>The story of the Inception architecture is one of ingenuity, iteration, and elegance in the field of deep learning. At a time when researchers were obsessed with increasing the depth and complexity of convolutional neural networks (CNNs) to improve accuracy on large-scale visual tasks, Google‚Äôs research team asked a different question: How can we go deeper without paying the full computational price? The answer was Inception‚Äîa family of architectures that offered a bold new design paradigm, prioritizing both <strong>computational efficiency and representational power</strong>. From <strong>Inception v1 (GoogLeNet)</strong> to <strong>Inception-ResNet v2</strong>, each version brought transformative ideas that would ripple throughout the deep learning community. This post unpacks the entire journey, layer by layer, innovation by innovation.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/20/inception.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/13/imagenet.html"></a></h2>
        <p class="post-meta">
          March 13, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="how-imagenet-taught-machines-to-see">How ImageNet Taught Machines to See</h1>

<h2 id="the-vision-behind-the-dataset">The Vision Behind the Dataset</h2>

<p>In the early 2000s, artificial intelligence was still stumbling in the dark when it came to understanding images. Researchers had built systems that could play chess or perform basic language tasks, but when it came to something a toddler could do‚Äîlike identifying a cat in a photo‚Äîmachines struggled. There was a glaring gap between the potential of machine learning and its real-world applications in vision.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/13/imagenet.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html"></a></h2>
        <p class="post-meta">
          March 6, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-random-illusion-why-adversarial-defenses-arent-as-robust-as-they-seem">The Random Illusion: Why Adversarial Defenses Aren‚Äôt as Robust as They Seem</h1>

<p>The field of adversarial machine learning is built on a paradox: models that perform impressively on natural data can be shockingly vulnerable to small, human-imperceptible perturbations. These adversarial examples expose a fragility in deep networks that could have serious consequences in security-critical domains like autonomous driving, medical imaging, or biometric authentication. Naturally, defenses against these attacks have been the subject of intense research. Among them, a seemingly simple strategy has gained popularity: <strong>random transformations</strong>. By applying random, often non-differentiable perturbations to input images‚Äîsuch as resizing, padding, cropping, JPEG compression, or color quantization‚Äîthese methods hope to break the adversary‚Äôs control over the gradients that guide attacks. At first glance, it seems effective. Robust accuracy increases. Attacks fail. But is this robustness genuine?</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/27/Polysemanticity.html"></a></h2>
        <p class="post-meta">
          February 27, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="block-geometry--everything-bagel-neurons-decoding-polysemanticity">Block Geometry &amp; Everything-Bagel Neurons: Decoding Polysemanticity</h1>

<h2 id="when-neurons-speak-in-tongues-why-polysemanticity-demands-a-theory-of-capacity">When Neurons Speak in Tongues: Why Polysemanticity Demands a Theory of Capacity</h2>

<p>Crack open a modern vision or language model and you‚Äôll run into a curious spectacle: the <strong>same</strong> unit flares for ‚Äúcat ears,‚Äù ‚Äústriped shirts,‚Äù <strong>and</strong> ‚Äúthe Eiffel Tower.‚Äù This phenomenon‚Äî<strong>polysemanticity</strong>‚Äîis more than a party trick. It frustrates attribution, muddies interpretability dashboards, and complicates any safety guarantee that relies on isolating <em>the</em> ‚Äúterrorism neuron‚Äù or ‚Äúprivacy-violation neuron.‚Äù</p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/27/Polysemanticity.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/13/tpa.html"></a></h2>
        <p class="post-meta">
          February 13, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-heads-to-factors-a-deep-dive-into-tensor-product-attention-and-the-t6-transformer">From Heads to Factors: A Deep Dive into Tensor Product Attention and the T6 Transformer</h1>

<p><em>A Transformer layer must preserve every key‚Äìvalue pair for every head, layer, and past token‚Äîa memory bill that rises linearly with context length.</em></p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/13/tpa.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/06/capa.html"></a></h2>
        <p class="post-meta">
          February 6, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-hidden-danger-of-ai-oversight-why-model-similarity-might-undermine-reliability"><strong>The Hidden Danger of AI Oversight: Why Model Similarity Might Undermine Reliability</strong></h1>

<p>Artificial Intelligence, particularly Large Language Models (LLMs) like ChatGPT, Llama, and Gemini, has witnessed extraordinary progress. These powerful models can effortlessly handle tasks from writing articles to solving complex reasoning problems. Yet, as these models become smarter, ensuring they‚Äôre behaving as intended is becoming harder for humans alone.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/06/capa.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/01/23/alexnetvsresnet.html"></a></h2>
        <p class="post-meta">
          January 23, 2025
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="how-alexnet-lit-the-spark-and-resnet-fanned-the-flames">How AlexNet Lit the Spark and ResNet Fanned the Flames</h1>

<p>In the ever-evolving landscape of deep learning, certain architectures have defined turning points in how neural networks are designed, trained, and understood. Among these, <strong>AlexNet</strong> and <strong>ResNet</strong> stand out as monumental contributions that shifted the paradigm of computer vision and image classification. Though separated by just three years, these two architectures reflect fundamentally different eras of deep learning‚ÄîAlexNet laid the groundwork for deep convolutional networks, while ResNet solved the pressing problems that deeper architectures introduced.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/01/23/alexnetvsresnet.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
  
    
  
    
  
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/12/12/AstroML.html"></a></h2>
        <p class="post-meta">
          December 12, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>, 
            
              <span class="inline-tag">Astrophysics</span>
            
          
        </p>
        <p><h1 id="exploring-astroml-machine-learning-among-the-stars">Exploring astroML: Machine Learning Among the Stars</h1>

<h2 id="the-astronomers-new-toolbox">The Astronomer‚Äôs New Toolbox</h2>

<p>Modern astronomy has evolved into a data-driven science. With massive sky surveys like SDSS (Sloan Digital Sky Survey), Pan-STARRS, and the upcoming LSST producing petabytes of data, traditional approaches no 
longer suffice. Manual inspection and simplistic models simply can‚Äôt scale with this astronomical data deluge. Enter <strong>astroML</strong>, a library that bridges the gap between astronomy and modern machine learning. 
astroML is a Python-based library built on top of familiar scientific computing tools like NumPy, SciPy, matplotlib, and scikit-learn. But what sets it apart is its thoughtful design ‚Äî tailored to real-world 
astronomical problems. From irregular time series to galaxy classification, astroML brings statistically sound and domain-specific tools to the fingertips of astronomers, physicists, and data scientists alike.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/12/12/AstroML.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/12/05/transformers.html"></a></h2>
        <p class="post-meta">
          December 5, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="attention-is-all-you-need-the-paper-that-changed-everything">Attention Is All You Need: The Paper That Changed Everything</h1>

<p>If you‚Äôve ever interacted with ChatGPT, asked an AI to summarize a document, or translated a phrase using Google Translate, you‚Äôre experiencing the legacy of a paper that redefined modern artificial intelligence. 
Published in 2017 by Vaswani et al., the paper <strong>‚ÄúAttention Is All You Need‚Äù</strong> introduced the world to the <strong>Transformer</strong> architecture. This seemingly simple idea ‚Äî that attention mechanisms alone can model 
complex language patterns without relying on recurrence or convolutions ‚Äî has since become the bedrock of nearly every major NLP system.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/12/05/transformers.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html"></a></h2>
        <p class="post-meta">
          November 21, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="teaching-ai-to-use-tools--the-right-way">Teaching AI to Use Tools ‚Äî The Right Way</h1>
<p><strong>A Deep Dive into Seal-Tools: The Dataset That Makes LLMs Smarter Agents</strong></p>

<p>Imagine asking your AI assistant to ‚Äúbook a flight to Paris, then schedule a taxi to the airport and convert the final bill to Euros.‚Äù Sounds simple, right? In reality, for most AI models, this isn‚Äôt just 
hard ‚Äî it‚Äôs nearly impossible to get right without human babysitting.</p>

<p>That‚Äôs because tool use, chaining functions, and executing multi-step operations <strong>requires structured reasoning</strong>, parameter handling, and format control ‚Äî things even the smartest LLMs struggle with today.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/14/tensors.html"></a></h2>
        <p class="post-meta">
          November 14, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>, 
            
              <span class="inline-tag">Astrophysics</span>
            
          
        </p>
        <p><h1 id="what-are-tensors">What Are Tensors?</h1>

<p>Tensors are fundamental mathematical objects that appear across various domains such as physics, computer science, and engineering. At their core, tensors are multi-dimensional arrays that generalize the 
concepts of scalars (single numbers), vectors (one-dimensional arrays), and matrices (two-dimensional arrays). Unlike simple arrays, tensors are not just containers of numbers‚Äîthey come with transformation 
rules that allow them to describe physical phenomena in a way that remains consistent across coordinate systems.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/14/tensors.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/07/React.html"></a></h2>
        <p class="post-meta">
          November 7, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-why-to-how-reacts-unified-reasoning-acting-paradigm">From ‚ÄúWhy‚Äù to ‚ÄúHow‚Äù: ReAct‚Äôs Unified Reasoning-Acting Paradigm</h1>

<p>Large language models (LLMs) have reshaped natural language processing by demonstrating impressive capabilities in text generation, summarization, and translation. Yet, as powerful as they are, 
these models often struggle when asked to perform complex, multi-step tasks that require deliberate planning and interaction with external information sources. Traditional chain-of-thought (CoT) 
prompting enables LLMs to articulate intermediate reasoning steps, but it remains confined to the model‚Äôs internal knowledge and inference capabilities. Conversely, action-based approaches have allowed 
models to execute external operations‚Äîsuch as querying an API or navigating an environment‚Äîbut lack explicit internal reasoning, leading to unexplainable or brittle behavior. The ReAct framework addresses 
this gap by synergizing reasoning and acting in a unified prompt-based paradigm that interleaves ‚Äúthoughts‚Äù and ‚Äúactions‚Äù to solve complex tasks more effectively and transparently.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/07/React.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html"></a></h2>
        <p class="post-meta">
          October 31, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-facts-to-insight-bridging-the-compositionality-gap-in-language-models">From Facts to Insight: Bridging the Compositionality Gap in Language Models</h1>

<p>Large language models (LLMs) such as GPT-3 have transformed natural language understanding by memorizing vast amounts of text. Yet, when faced with questions that require <strong>combining</strong> multiple pieces 
of knowledge‚Äîso-called <em>compositional reasoning</em>‚Äîeven the biggest models stumble. In their paper <em>Measuring and Narrowing the Compositionality Gap in Language Models</em>, Press et al. introduce a new metric
for this shortfall, show that it persists despite model scale, and propose practical prompting techniques to close it.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/24/LoRA.html"></a></h2>
        <p class="post-meta">
          October 24, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="lora-a-breakthrough-in-efficient-fine-tuning-of-large-language-models">LoRA: A Breakthrough in Efficient Fine-Tuning of Large Language Models</h1>

<p>As large language models (LLMs) like GPT-3, LLaMA, and BERT continue to grow in size and influence, one challenge becomes increasingly apparent: while these models offer exceptional capabilities, 
<strong>adapting them for new tasks remains expensive and resource-intensive</strong>. Fine-tuning a model with billions of parameters typically requires large datasets, massive compute power, 
and hours or even days of training time ‚Äî luxuries not everyone can afford.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/24/LoRA.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html"></a></h2>
        <p class="post-meta">
          October 17, 2024
          
            ‚Äî Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="fine-tuning-language-models-welcome-to-the-nerdy-playground-of-llms">Fine-Tuning Language Models: Welcome to the Nerdy Playground of LLMs</h1>
<p><em>From LoRA to RLHF ‚Äî and all the acronyms in between</em></p>

<p>So, you‚Äôve got your hands on a fancy pre-trained language model. Great. It‚Äôs read more text than any human ever will, speaks in Shakespearean iambic pentameter <em>and</em> Python, and can tell you the capital of Burkina Faso at 3 AM.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html" class="read-more">Read more ‚Üí</a>
      </li>
    
  
    
  
</ul>

    </main>

    <footer class="site-footer">
      <div class="container">
        <p>¬© 2025 Rahul Thakur ‚Ä¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
