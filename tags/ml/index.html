<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Posts tagged ML | Tensors & Quarks</title>
    <link rel="stylesheet" href="/tensorandquarks.github.io/assets/style.css" />

    <!-- ğŸŒ“ Dark Mode Script -->
    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }

      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- âœ… MathJax Support -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Posts tagged ML | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Posts tagged ML" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/" />
<meta property="og:url" content="https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Posts tagged ML" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Posts tagged ML","url":"https://raahul-thakur.github.io/tensorandquarks.github.io/tags/ml/"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/tensorandquarks.github.io/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/tensorandquarks.github.io/">Home</a>
          <a href="/tensorandquarks.github.io/about.html">About</a>
          <button onclick="toggleDarkMode()">ğŸŒ“</button>
        </nav>
      </div>
    </header>

    <main class="container">
      <h1>Posts tagged ML</h1>

<ul class="post-list">
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html"></a></h2>
        <p class="post-meta">
          March 28, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="-on-the-biology-of-a-large-language-model">ğŸ§  On the Biology of a Large Language Model</h1>
<h2 id="exploring-the-hidden-anatomy-of-claude-35-haiku">Exploring the Hidden Anatomy of Claude 3.5 Haiku</h2>

<p><img src="/assets/images/llm_blackbox/A_2D_digital_diagram_presents_a_simplified_represe.png" alt="Attribution Graph Overview" /></p>

<p>In recent months, interpretability research in AI has taken a leap forward, and Anthropicâ€™s work on attribution graphs stands at the forefront. Their new article, <em>â€œOn the Biology of a Large Language Model,â€</em> investigates the internal mechanisms of Claude 3.5 Haiku, a compact yet capable language model released in late 2024. But what makes this work truly groundbreaking is not just what the model does â€” itâ€™s how the researchers dissect its â€œthought processâ€ to reveal the complex internal machinery that governs its behavior.</p>

<p>At the heart of this research lies a fascinating new tool: the attribution graph. These graphs are like wiring diagrams that trace how specific outputs arise from individual components inside a model â€” not unlike how neuroscientists track neural pathways to understand the brain. Instead of seeing the model as an opaque black box, attribution graphs allow us to visualize how neurons, attention heads, and internal features come together to form coherent reasoning, memory, and even self-control circuits.</p>

<hr />

<h2 id="-case-studies-in-model-biology">ğŸ§© Case Studies in Model Biology</h2>

<h3 id="-multi-step-reasoning">ğŸ” Multi-step Reasoning</h3>
<p><img src="/assets/images/llm_blackbox/A_diagram_in_the_digital_2D_vector_graphic_medium_.png" alt="Multi-step Reasoning Circuit" /></p>

<h3 id="-poetry-planning">ğŸ“ Poetry Planning</h3>
<p><img src="/assets/images/llm_blackbox/A_2D_digital_diagram_features_interconnected_nodes.png" alt="Poetry Planning Diagram" /></p>

<h3 id="-multilingual-processing">ğŸŒ Multilingual Processing</h3>
<p><img src="/assets/images/llm_blackbox/A_2D_digital_diagram_features_nodes_representing_b.png" alt="Language Circuit Comparison" /></p>

<h3 id="-arithmetic-modules">â• Arithmetic Modules</h3>
<p><img src="/assets/images/llm_blackbox/A_diagram_presents_four_horizontal_bar_graphs_stac.png" alt="Arithmetic Circuit Visualization" /></p>

<h3 id="-medical-diagnostics-and-hallucination-risk">ğŸ§¬ Medical Diagnostics and Hallucination Risk</h3>
<p>But not everything is so neat. In tasks involving medical diagnosis, Claude activates a rich set of features linked to symptoms and conditions. Yet these circuits also highlight one of the core limitations: the potential for hallucinations.</p>

<h3 id="-refusals-and-jailbreaks">ğŸš« Refusals and Jailbreaks</h3>
<p><img src="/assets/images/llm_blackbox/A_directed_graph_diagram_in_a_digital_medium_illus.png" alt="Refusal Bypass Diagram" /></p>

<h3 id="-chain-of-thought-faithfulness">ğŸ§­ Chain-of-Thought Faithfulness</h3>
<p><img src="/assets/images/llm_blackbox/A_pair_of_side-by-side_heatmap_visualizations_titl.png" alt="Faithful vs Unfaithful CoT" /></p>

<hr />

<h2 id="-modular-circuit-insights">ğŸ§  Modular Circuit Insights</h2>
<p><img src="/assets/images/llm_blackbox/A_2D_digital_diagram_depicts_an_attribution_graph_.png" alt="Modular Cortex Diagram" /></p>

<h3 id="-component-specialization-and-task-allocation">ğŸ”¬ Component Specialization and Task Allocation</h3>
<p><img src="/assets/images/llm_blackbox/head_importance.png" alt="Head Importance Across Tasks" /><br />
<img src="/assets/images/llm_blackbox/component_contribution.png" alt="Attention vs MLP Contribution by Task" /></p>

<hr />

<h2 id="-emergence-of-behavior">ğŸ“ˆ Emergence of Behavior</h2>
<p><img src="/assets/images/llm_blackbox/circuit_emergence.png" alt="Circuit Emergence Timeline" /></p>

<h2 id="-token-level-attribution">ğŸ§® Token-Level Attribution</h2>
<p><img src="/assets/images/llm_blackbox/token_attribution.png" alt="Token Attribution Heatmap" /></p>

<hr />

<h2 id="-assessment-why-this-research-matters">ğŸ§ª Assessment: Why This Research Matters</h2>

<p>This paper represents a major leap in our journey to truly understand and control the models we build. In an era where large language models are becoming central to everything from education and entertainment to scientific discovery and national security, interpretability is no longer optional â€” itâ€™s foundational.</p>

<p>Until now, most interpretability techniques have focused on shallow post-hoc explanations. Attribution graphs, in contrast, present a causal and modular view of model computation.</p>

<h3 id="-key-problems-this-research-helps-solve">âœ… Key Problems This Research Helps Solve</h3>

<ul>
  <li>Debugging hallucinations and false memory recall</li>
  <li>Understanding misalignment and potential deception</li>
  <li>Tracing harmful outputs to specific circuits</li>
  <li>Improving faithfulness in chain-of-thought prompting</li>
  <li>Isolating reusable components for modular training</li>
  <li>Auditing refusals and jailbreak vulnerabilities</li>
  <li>Interpreting multilingual and multi-task behavior</li>
</ul>

<h3 id="-limitations-of-the-paper">â— Limitations of the Paper</h3>

<ul>
  <li><strong>Scalability</strong> to larger models like Claude 3.5 Sonnet or GPT-4</li>
  <li><strong>Subjectivity</strong> in interpreting circuit purpose</li>
  <li><strong>No deep dive into training-time emergence</strong></li>
  <li>Risk of <strong>confirmation bias</strong> in attribution analysis</li>
</ul>

<hr />

<h3 id="-attribution-diagnostics">ğŸ” Attribution Diagnostics</h3>
<p><img src="/assets/images/llm_blackbox/A_2x2_grid_diagram_with_attribution_error_types_is.png" alt="Attribution Error Quadrants" /><br />
<img src="/assets/images/llm_blackbox/A_diagram_in_the_image_illustrates_concepts_relate.png" alt="Stages of Attribution Flow" /></p>

<hr />

<h2 id="-final-reflection">ğŸ§  Final Reflection</h2>

<p>In sum, <em>â€œOn the Biology of a Large Language Modelâ€</em> is not just a clever metaphor â€” itâ€™s a manifesto for the next era of model interpretability. It doesnâ€™t just show that language models compute â€” it shows how they think.</p>

<p>And thatâ€™s a future worth decoding.</p>

<hr />

<h2 id="-reference">ğŸ”— Reference</h2>
<p>ğŸ“„ <a href="https://transformer-circuits.pub/2025/attribution-graphs/biology.html">Read the original paper on Anthropicâ€™s official blog</a></p>
</p>
        <a href="/tensorandquarks.github.io/2025/03/28/llm-blackbox-pt1.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/20/inception.html"></a></h2>
        <p class="post-meta">
          March 20, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-deepening-layers-of-inception-a-journey-through-cnn-time">The Deepening Layers of Inception: A Journey Through CNN Time</h1>

<p>The story of the Inception architecture is one of ingenuity, iteration, and elegance in the field of deep learning. At a time when researchers were obsessed with increasing the depth and complexity of convolutional neural networks (CNNs) to improve accuracy on large-scale visual tasks, Googleâ€™s research team asked a different question: How can we go deeper without paying the full computational price? The answer was Inceptionâ€”a family of architectures that offered a bold new design paradigm, prioritizing both <strong>computational efficiency and representational power</strong>. From <strong>Inception v1 (GoogLeNet)</strong> to <strong>Inception-ResNet v2</strong>, each version brought transformative ideas that would ripple throughout the deep learning community. This post unpacks the entire journey, layer by layer, innovation by innovation.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/20/inception.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/13/imagenet.html"></a></h2>
        <p class="post-meta">
          March 13, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="how-imagenet-taught-machines-to-see">How ImageNet Taught Machines to See</h1>

<h2 id="the-vision-behind-the-dataset">The Vision Behind the Dataset</h2>

<p>In the early 2000s, artificial intelligence was still stumbling in the dark when it came to understanding images. Researchers had built systems that could play chess or perform basic language tasks, but when it came to something a toddler could doâ€”like identifying a cat in a photoâ€”machines struggled. There was a glaring gap between the potential of machine learning and its real-world applications in vision.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/13/imagenet.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html"></a></h2>
        <p class="post-meta">
          March 6, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-random-illusion-why-adversarial-defenses-arent-as-robust-as-they-seem">The Random Illusion: Why Adversarial Defenses Arenâ€™t as Robust as They Seem</h1>

<p>The field of adversarial machine learning is built on a paradox: models that perform impressively on natural data can be shockingly vulnerable to small, human-imperceptible perturbations. These adversarial examples expose a fragility in deep networks that could have serious consequences in security-critical domains like autonomous driving, medical imaging, or biometric authentication. Naturally, defenses against these attacks have been the subject of intense research. Among them, a seemingly simple strategy has gained popularity: <strong>random transformations</strong>. By applying random, often non-differentiable perturbations to input imagesâ€”such as resizing, padding, cropping, JPEG compression, or color quantizationâ€”these methods hope to break the adversaryâ€™s control over the gradients that guide attacks. At first glance, it seems effective. Robust accuracy increases. Attacks fail. But is this robustness genuine?</p>

</p>
        <a href="/tensorandquarks.github.io/2025/03/06/random-transformation.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/27/Polysemanticity.html"></a></h2>
        <p class="post-meta">
          February 27, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="block-geometry--everything-bagel-neurons-decoding-polysemanticity">Block Geometry &amp; Everything-Bagel Neurons: Decoding Polysemanticity</h1>

<h2 id="when-neurons-speak-in-tongues-why-polysemanticity-demands-a-theory-of-capacity">When Neurons Speak in Tongues: Why Polysemanticity Demands a Theory of Capacity</h2>

<p>Crack open a modern vision or language model and youâ€™ll run into a curious spectacle: the <strong>same</strong> unit flares for â€œcat ears,â€ â€œstriped shirts,â€ <strong>and</strong> â€œthe Eiffel Tower.â€ This phenomenonâ€”<strong>polysemanticity</strong>â€”is more than a party trick. It frustrates attribution, muddies interpretability dashboards, and complicates any safety guarantee that relies on isolating <em>the</em> â€œterrorism neuronâ€ or â€œprivacy-violation neuron.â€</p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/27/Polysemanticity.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/13/tpa.html"></a></h2>
        <p class="post-meta">
          February 13, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-heads-to-factors-a-deep-dive-into-tensor-product-attention-and-the-t6-transformer">From Heads to Factors: A Deep Dive into Tensor Product Attention and the T6 Transformer</h1>

<p><em>A Transformer layer must preserve every keyâ€“value pair for every head, layer, and past tokenâ€”a memory bill that rises linearly with context length.</em></p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/13/tpa.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/02/06/capa.html"></a></h2>
        <p class="post-meta">
          February 6, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="the-hidden-danger-of-ai-oversight-why-model-similarity-might-undermine-reliability"><strong>The Hidden Danger of AI Oversight: Why Model Similarity Might Undermine Reliability</strong></h1>

<p>Artificial Intelligence, particularly Large Language Models (LLMs) like ChatGPT, Llama, and Gemini, has witnessed extraordinary progress. These powerful models can effortlessly handle tasks from writing articles to solving complex reasoning problems. Yet, as these models become smarter, ensuring theyâ€™re behaving as intended is becoming harder for humans alone.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/02/06/capa.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2025/01/23/alexnetvsresnet.html"></a></h2>
        <p class="post-meta">
          January 23, 2025
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="how-alexnet-lit-the-spark-and-resnet-fanned-the-flames">How AlexNet Lit the Spark and ResNet Fanned the Flames</h1>

<p>In the ever-evolving landscape of deep learning, certain architectures have defined turning points in how neural networks are designed, trained, and understood. Among these, <strong>AlexNet</strong> and <strong>ResNet</strong> stand out as monumental contributions that shifted the paradigm of computer vision and image classification. Though separated by just three years, these two architectures reflect fundamentally different eras of deep learningâ€”AlexNet laid the groundwork for deep convolutional networks, while ResNet solved the pressing problems that deeper architectures introduced.</p>

</p>
        <a href="/tensorandquarks.github.io/2025/01/23/alexnetvsresnet.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
  
    
  
    
  
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/12/12/AstroML.html"></a></h2>
        <p class="post-meta">
          December 12, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>, 
            
              <span class="inline-tag">Astrophysics</span>
            
          
        </p>
        <p><h1 id="exploring-astroml-machine-learning-among-the-stars">Exploring astroML: Machine Learning Among the Stars</h1>

<h2 id="the-astronomers-new-toolbox">The Astronomerâ€™s New Toolbox</h2>

<p>Modern astronomy has evolved into a data-driven science. With massive sky surveys like SDSS (Sloan Digital Sky Survey), Pan-STARRS, and the upcoming LSST producing petabytes of data, traditional approaches no 
longer suffice. Manual inspection and simplistic models simply canâ€™t scale with this astronomical data deluge. Enter <strong>astroML</strong>, a library that bridges the gap between astronomy and modern machine learning. 
astroML is a Python-based library built on top of familiar scientific computing tools like NumPy, SciPy, matplotlib, and scikit-learn. But what sets it apart is its thoughtful design â€” tailored to real-world 
astronomical problems. From irregular time series to galaxy classification, astroML brings statistically sound and domain-specific tools to the fingertips of astronomers, physicists, and data scientists alike.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/12/12/AstroML.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/12/05/transformers.html"></a></h2>
        <p class="post-meta">
          December 5, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="attention-is-all-you-need-the-paper-that-changed-everything">Attention Is All You Need: The Paper That Changed Everything</h1>

<p>If youâ€™ve ever interacted with ChatGPT, asked an AI to summarize a document, or translated a phrase using Google Translate, youâ€™re experiencing the legacy of a paper that redefined modern artificial intelligence. 
Published in 2017 by Vaswani et al., the paper <strong>â€œAttention Is All You Needâ€</strong> introduced the world to the <strong>Transformer</strong> architecture. This seemingly simple idea â€” that attention mechanisms alone can model 
complex language patterns without relying on recurrence or convolutions â€” has since become the bedrock of nearly every major NLP system.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/12/05/transformers.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html"></a></h2>
        <p class="post-meta">
          November 21, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="teaching-ai-to-use-tools--the-right-way">Teaching AI to Use Tools â€” The Right Way</h1>
<p><strong>A Deep Dive into Seal-Tools: The Dataset That Makes LLMs Smarter Agents</strong></p>

<p>Imagine asking your AI assistant to â€œbook a flight to Paris, then schedule a taxi to the airport and convert the final bill to Euros.â€ Sounds simple, right? In reality, for most AI models, this isnâ€™t just 
hard â€” itâ€™s nearly impossible to get right without human babysitting.</p>

<p>Thatâ€™s because tool use, chaining functions, and executing multi-step operations <strong>requires structured reasoning</strong>, parameter handling, and format control â€” things even the smartest LLMs struggle with today.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/21/seal-tools.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/14/tensors.html"></a></h2>
        <p class="post-meta">
          November 14, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>, 
            
              <span class="inline-tag">Astrophysics</span>
            
          
        </p>
        <p><h1 id="what-are-tensors">What Are Tensors?</h1>

<p>Tensors are fundamental mathematical objects that appear across various domains such as physics, computer science, and engineering. At their core, tensors are multi-dimensional arrays that generalize the 
concepts of scalars (single numbers), vectors (one-dimensional arrays), and matrices (two-dimensional arrays). Unlike simple arrays, tensors are not just containers of numbersâ€”they come with transformation 
rules that allow them to describe physical phenomena in a way that remains consistent across coordinate systems.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/14/tensors.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/11/07/React.html"></a></h2>
        <p class="post-meta">
          November 7, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-why-to-how-reacts-unified-reasoning-acting-paradigm">From â€œWhyâ€ to â€œHowâ€: ReActâ€™s Unified Reasoning-Acting Paradigm</h1>

<p>Large language models (LLMs) have reshaped natural language processing by demonstrating impressive capabilities in text generation, summarization, and translation. Yet, as powerful as they are, 
these models often struggle when asked to perform complex, multi-step tasks that require deliberate planning and interaction with external information sources. Traditional chain-of-thought (CoT) 
prompting enables LLMs to articulate intermediate reasoning steps, but it remains confined to the modelâ€™s internal knowledge and inference capabilities. Conversely, action-based approaches have allowed 
models to execute external operationsâ€”such as querying an API or navigating an environmentâ€”but lack explicit internal reasoning, leading to unexplainable or brittle behavior. The ReAct framework addresses 
this gap by synergizing reasoning and acting in a unified prompt-based paradigm that interleaves â€œthoughtsâ€ and â€œactionsâ€ to solve complex tasks more effectively and transparently.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/11/07/React.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html"></a></h2>
        <p class="post-meta">
          October 31, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="from-facts-to-insight-bridging-the-compositionality-gap-in-language-models">From Facts to Insight: Bridging the Compositionality Gap in Language Models</h1>

<p>Large language models (LLMs) such as GPT-3 have transformed natural language understanding by memorizing vast amounts of text. Yet, when faced with questions that require <strong>combining</strong> multiple pieces 
of knowledgeâ€”so-called <em>compositional reasoning</em>â€”even the biggest models stumble. In their paper <em>Measuring and Narrowing the Compositionality Gap in Language Models</em>, Press et al. introduce a new metric
for this shortfall, show that it persists despite model scale, and propose practical prompting techniques to close it.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/31/Gap-in-llms.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/24/LoRA.html"></a></h2>
        <p class="post-meta">
          October 24, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="lora-a-breakthrough-in-efficient-fine-tuning-of-large-language-models">LoRA: A Breakthrough in Efficient Fine-Tuning of Large Language Models</h1>

<p>As large language models (LLMs) like GPT-3, LLaMA, and BERT continue to grow in size and influence, one challenge becomes increasingly apparent: while these models offer exceptional capabilities, 
<strong>adapting them for new tasks remains expensive and resource-intensive</strong>. Fine-tuning a model with billions of parameters typically requires large datasets, massive compute power, 
and hours or even days of training time â€” luxuries not everyone can afford.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/24/LoRA.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
      <li class="post-card">
        <h2><a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html"></a></h2>
        <p class="post-meta">
          October 17, 2024
          
            â€” Tags:
            
              <span class="inline-tag">ML</span>
            
          
        </p>
        <p><h1 id="fine-tuning-language-models-welcome-to-the-nerdy-playground-of-llms">Fine-Tuning Language Models: Welcome to the Nerdy Playground of LLMs</h1>
<p><em>From LoRA to RLHF â€” and all the acronyms in between</em></p>

<p>So, youâ€™ve got your hands on a fancy pre-trained language model. Great. Itâ€™s read more text than any human ever will, speaks in Shakespearean iambic pentameter <em>and</em> Python, and can tell you the capital of Burkina Faso at 3 AM.</p>

</p>
        <a href="/tensorandquarks.github.io/2024/10/17/fine-tuning-llms.html" class="read-more">Read more â†’</a>
      </li>
    
  
    
  
</ul>

    </main>

    <footer class="site-footer">
      <div class="container">
        <p>Â© 2025 Rahul Thakur â€¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
