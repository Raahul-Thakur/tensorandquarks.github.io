<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Home | Tensors & Quarks</title>
    <link rel="stylesheet" href="/assets/style.css" />

    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }
      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Page 3 of 8 for Home | Tensors &amp; Quarks</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Home" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Exploring the intersection of physics and machine learning." />
<meta property="og:description" content="Exploring the intersection of physics and machine learning." />
<link rel="canonical" href="https://www.tensorsandquarks.space/page3/" />
<meta property="og:url" content="https://www.tensorsandquarks.space/page3/" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="website" />
<link rel="prev" href="https://www.tensorsandquarks.space/page2" />
<link rel="next" href="https://www.tensorsandquarks.space/page4" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Home" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Rahul Thakur"},"description":"Exploring the intersection of physics and machine learning.","headline":"Home","url":"https://www.tensorsandquarks.space/page3/"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/">Home</a>
          <a href="/about.html">About</a>
          <button onclick="toggleDarkMode()">üåì</button>
        </nav>
      </div>
    </header>

    <main class="container">
      <div class="hero">
        <h1>Welcome to Tensors & Quarks</h1>
        <p>Exploring the cosmos of <strong>Physics</strong> & the depths of <strong>Machine Learning</strong>.</p>
      </div>

      <div class="tag-filter">
        <strong>Filter by Tag:</strong>
        <a href="/tags/ml/">ML</a> |
        <a href="/tags/astrophysics/">Astrophysics</a> |
        <a href="/tags/misc/">Misc</a>
      </div>

      <h2>Latest Posts</h2>
      <ul class="post-list">
        
          <li class="post-card">
            <h3><a href="/2025/04/03/llm-blackbox-pt2.html"></a></h3>
            <p class="post-meta">
              April 3, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-circuits-to-cognition-following-the-thoughts-of-claude-35">From Circuits to Cognition: Following the Thoughts of Claude 3.5</h1>
<h2 id="decoding-anthropics-next-step-in-understanding-language-models">Decoding Anthropic‚Äôs Next Step in Understanding Language Models</h2>

<p>In my previous post, we explored <em>‚ÄúOn the Biology of a Large Language Model‚Äù</em>, Anthropic‚Äôs groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using <strong>attribution graphs</strong>. These graphs offered a glimpse into the hidden architecture of reasoning ‚Äî showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates.</p>

</p>
            <a href="/2025/04/03/llm-blackbox-pt2.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/03/28/llm-blackbox-pt1.html"></a></h3>
            <p class="post-meta">
              March 28, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="from-black-box-to-blueprint-tracing-the-logic-of-claude-35">From Black Box to Blueprint: Tracing the Logic of Claude 3.5</h1>
<h2 id="exploring-the-hidden-anatomy-of-a-language-model">Exploring the Hidden Anatomy of a Language Model</h2>

<p>In the age of large language models, capability often outpaces comprehension. Models like Claude 3.5 can write poetry, solve logic puzzles, and navigate multilingual queries ‚Äî but we still don‚Äôt fully understand <em>how</em>. Beneath their fluent outputs lies a vast architecture of layers, weights, and attention heads that, until recently, remained largely inscrutable.</p>

</p>
            <a href="/2025/03/28/llm-blackbox-pt1.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/03/20/inception.html"></a></h3>
            <p class="post-meta">
              March 20, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="the-deepening-layers-of-inception-a-journey-through-cnn-time">The Deepening Layers of Inception: A Journey Through CNN Time</h1>

<p>The story of the Inception architecture is one of ingenuity, iteration, and elegance in the field of deep learning. At a time when researchers were obsessed with increasing the depth and complexity of convolutional neural networks (CNNs) to improve accuracy on large-scale visual tasks, Google‚Äôs research team asked a different question: How can we go deeper without paying the full computational price? The answer was Inception‚Äîa family of architectures that offered a bold new design paradigm, prioritizing both <strong>computational efficiency and representational power</strong>. From <strong>Inception v1 (GoogLeNet)</strong> to <strong>Inception-ResNet v2</strong>, each version brought transformative ideas that would ripple throughout the deep learning community. This post unpacks the entire journey, layer by layer, innovation by innovation.</p>

</p>
            <a href="/2025/03/20/inception.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/03/13/imagenet.html"></a></h3>
            <p class="post-meta">
              March 13, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="how-imagenet-taught-machines-to-see">How ImageNet Taught Machines to See</h1>

<h2 id="the-vision-behind-the-dataset">The Vision Behind the Dataset</h2>

<p>In the early 2000s, artificial intelligence was still stumbling in the dark when it came to understanding images. Researchers had built systems that could play chess or perform basic language tasks, but when it came to something a toddler could do‚Äîlike identifying a cat in a photo‚Äîmachines struggled. There was a glaring gap between the potential of machine learning and its real-world applications in vision.</p>

</p>
            <a href="/2025/03/13/imagenet.html" class="read-more">Read more ‚Üí</a>
          </li>
        
          <li class="post-card">
            <h3><a href="/2025/03/06/random-transformation.html"></a></h3>
            <p class="post-meta">
              March 6, 2025
              
                ‚Äî Tags:
                
                  <span class="inline-tag">ML</span>
                
              
            </p>
            <p><h1 id="the-random-illusion-why-adversarial-defenses-arent-as-robust-as-they-seem">The Random Illusion: Why Adversarial Defenses Aren‚Äôt as Robust as They Seem</h1>

<p>The field of adversarial machine learning is built on a paradox: models that perform impressively on natural data can be shockingly vulnerable to small, human-imperceptible perturbations. These adversarial examples expose a fragility in deep networks that could have serious consequences in security-critical domains like autonomous driving, medical imaging, or biometric authentication. Naturally, defenses against these attacks have been the subject of intense research. Among them, a seemingly simple strategy has gained popularity: <strong>random transformations</strong>. By applying random, often non-differentiable perturbations to input images‚Äîsuch as resizing, padding, cropping, JPEG compression, or color quantization‚Äîthese methods hope to break the adversary‚Äôs control over the gradients that guide attacks. At first glance, it seems effective. Robust accuracy increases. Attacks fail. But is this robustness genuine?</p>

</p>
            <a href="/2025/03/06/random-transformation.html" class="read-more">Read more ‚Üí</a>
          </li>
        
      </ul>

      <div class="pagination">
        
          <a href="/page2">&larr; Newer Posts</a>
        

        <span>Page 3 of 8</span>

        
          <a href="/page4">Older Posts &rarr;</a>
        
      </div>
    </main>

    <footer class="site-footer">
      <div class="container">
        <p>¬© 2025 Rahul Thakur ‚Ä¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
