<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title> | Tensors & Quarks</title>
    <link rel="stylesheet" href="/assets/style.css" />

    <!-- ğŸŒ“ Dark Mode Script -->
    <script>
      function toggleDarkMode() {
        document.body.classList.toggle("dark");
        localStorage.setItem("theme", document.body.classList.contains("dark") ? "dark" : "light");
      }

      window.onload = () => {
        if (localStorage.getItem("theme") === "dark") {
          document.body.classList.add("dark");
        }
      };
    </script>

    <!-- âœ… MathJax Support -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Tensors &amp; Quarks | Exploring the intersection of physics and machine learning.</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Tensors &amp; Quarks" />
<meta name="author" content="Rahul Thakur" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="From Circuits to Cognition: Following the Thoughts of Claude 3.5 Decoding Anthropicâ€™s Next Step in Understanding Language Models In my previous post, we explored â€œOn the Biology of a Large Language Modelâ€, Anthropicâ€™s groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using attribution graphs. These graphs offered a glimpse into the hidden architecture of reasoning â€” showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates." />
<meta property="og:description" content="From Circuits to Cognition: Following the Thoughts of Claude 3.5 Decoding Anthropicâ€™s Next Step in Understanding Language Models In my previous post, we explored â€œOn the Biology of a Large Language Modelâ€, Anthropicâ€™s groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using attribution graphs. These graphs offered a glimpse into the hidden architecture of reasoning â€” showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates." />
<link rel="canonical" href="https://www.tensorsandquarks.space/2025/04/03/llm-blackbox-pt2.html" />
<meta property="og:url" content="https://www.tensorsandquarks.space/2025/04/03/llm-blackbox-pt2.html" />
<meta property="og:site_name" content="Tensors &amp; Quarks" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-04-03T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Tensors &amp; Quarks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Rahul Thakur"},"dateModified":"2025-04-03T00:00:00+00:00","datePublished":"2025-04-03T00:00:00+00:00","description":"From Circuits to Cognition: Following the Thoughts of Claude 3.5 Decoding Anthropicâ€™s Next Step in Understanding Language Models In my previous post, we explored â€œOn the Biology of a Large Language Modelâ€, Anthropicâ€™s groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using attribution graphs. These graphs offered a glimpse into the hidden architecture of reasoning â€” showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates.","headline":"Tensors &amp; Quarks","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.tensorsandquarks.space/2025/04/03/llm-blackbox-pt2.html"},"url":"https://www.tensorsandquarks.space/2025/04/03/llm-blackbox-pt2.html"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>
    <header class="site-header">
      <div class="container header-flex">
        <div class="branding">
          <img src="/assets/images/bio-photo.jpeg" alt="Rahul" class="profile-pic">
          <h1 class="site-title">Tensors & Quarks</h1>
        </div>
        <nav class="nav">
          <a href="/">Home</a>
          <a href="/about.html">About</a>
          <button onclick="toggleDarkMode()">ğŸŒ“</button>
        </nav>
      </div>
    </header>

    <main class="container">
      <h1 id="from-circuits-to-cognition-following-the-thoughts-of-claude-35">From Circuits to Cognition: Following the Thoughts of Claude 3.5</h1>
<h2 id="decoding-anthropics-next-step-in-understanding-language-models">Decoding Anthropicâ€™s Next Step in Understanding Language Models</h2>

<p>In my previous post, we explored <em>â€œOn the Biology of a Large Language Modelâ€</em>, Anthropicâ€™s groundbreaking research that mapped the internal circuits of Claude 3.5 Haiku using <strong>attribution graphs</strong>. These graphs offered a glimpse into the hidden architecture of reasoning â€” showing how Claude decomposes questions, plans poems, reasons across languages, and even hallucinates.</p>

<!--more-->

<p>But what if we could go a step further?</p>

<p>What if, instead of just identifying the components responsible for thought, we could <strong>trace a single idea as it unfolds inside the model â€” moment by moment, token by token</strong>?</p>

<p>Thatâ€™s exactly what Anthropic attempts in their new article: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model"><em>â€œTracing the Thoughts of a Language Modelâ€</em></a>. It builds directly on the foundation of attribution graphs and pushes us deeper into the mind of a transformer â€” not to observe its structure, but to follow its <em>thinking</em>.</p>

<hr />

<h2 id="thought-as-a-path-not-just-a-spark">Thought as a Path, Not Just a Spark</h2>

<p>The original paper dissected how circuits activate to solve sub-tasks â€” arithmetic, rhyme planning, multilingual parsing. In this new work, Anthropic tracks what happens <strong>after</strong> a feature activates. Where does it go? What does it influence? What follows?</p>

<p>Imagine prompting Claude with a sentence like:</p>

<blockquote>
  <p>â€œDescribe how biology influences philosophy.â€</p>
</blockquote>

<p>This prompt doesnâ€™t just activate features for â€œbiologyâ€ â€” it sets off a chain reaction. The â€œbiologyâ€ feature interacts with others: â€œevolution,â€ â€œDarwin,â€ â€œethics,â€ â€œreasoning,â€ and eventually, â€œphilosophy.â€ Using <strong>token-by-token attribution graphs</strong>, Anthropic visualizes how one thought <strong>cascades</strong> through the network.</p>

<p>These â€œthought chainsâ€ arenâ€™t linear. Some tokens reinforce earlier ideas. Others suppress or redirect them. Concepts may disappear temporarily, only to resurface later with stronger activation â€” a kind of <strong>working memory</strong>. This dynamic flow is what Anthropic now calls <em>thought tracing</em>.</p>

<hr />

<h2 id="a-model-that-strategizes-yes--and-we-can-watch-it">A Model That Strategizes? Yes â€” and We Can Watch It</h2>

<p>Just like in the earlier poetry example, Claude doesnâ€™t merely complete sentences â€” it <strong>plans</strong>. In the new study, the researchers show how the model can begin forming a mental structure even before certain tokens are generated.</p>

<p>For instance, features related to â€œethicsâ€ might activate <strong>before</strong> the word appears, because the model anticipates its relevance to â€œbiology + philosophy.â€ Attribution graphs reveal how these anticipations manifest as <strong>early activations</strong> of supporting features, which then guide downstream generation.</p>

<p>This is a profound shift in how we think about LLMs: not as reactionary next-word predictors, but as <strong>goal-conditioned planners</strong>. And now, we can trace those goals step-by-step.</p>

<hr />

<h2 id="a-second-brain-inside-claude">A Second Brain Inside Claude</h2>

<p>So what exactly is being revealed here?</p>

<p>The new article essentially treats the LLM as a <strong>second brain</strong> â€” not just in metaphor, but in methodology. Where the original paper mapped the â€œorgansâ€ (modular circuits), this one traces <strong>synaptic firing</strong> across those modules in real time.</p>

<p>Itâ€™s a neuroscience-inspired look at AI, and it suggests that Claude builds meaning not by memorizing facts, but by <strong>composing them dynamically</strong> across internal systems.</p>

<p>In this way, â€œthoughtâ€ becomes not a static activation, but a <strong>trajectory</strong> â€” a living path formed and updated as the model processes the prompt.</p>

<hr />

<h2 id="prompting-with-precision-the-future-of-language-engineering">Prompting with Precision: The Future of Language Engineering</h2>

<p>One practical implication? <strong>Prompt engineering could evolve into thought-path design.</strong></p>

<p>If we understand which phrases activate which paths, we could design prompts that:</p>
<ul>
  <li>Strengthen the recall of helpful circuits</li>
  <li>Suppress misleading associations</li>
  <li>Steer reasoning toward desired conclusions</li>
</ul>

<p>Itâ€™s no longer guesswork â€” itâ€™s <strong>cognitive scaffolding</strong>.</p>

<p>This insight also holds promise for safety research. Tracing how harmful thoughts arise â€” and from which token or feature â€” gives us a tool to <strong>preempt hallucinations and jailbreaks</strong> with surgical precision.</p>

<hr />

<h2 id="a-new-lens-for-interpretability">A New Lens for Interpretability</h2>

<p>In many ways, this new article doesnâ€™t replace the original paper â€” it <strong>completes it</strong>.</p>

<table>
  <thead>
    <tr>
      <th><strong>Biology of a Language Model</strong></th>
      <th><strong>Tracing the Thoughts</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Maps internal features and circuits</td>
      <td>Traces real-time activation of those features</td>
    </tr>
    <tr>
      <td>Shows where reasoning lives</td>
      <td>Shows how reasoning moves</td>
    </tr>
    <tr>
      <td>Highlights modularity</td>
      <td>Highlights dynamics</td>
    </tr>
    <tr>
      <td>Inspired by anatomy</td>
      <td>Inspired by cognition</td>
    </tr>
  </tbody>
</table>

<p>Together, they shift the view of LLMs from static black boxes to <strong>living systems</strong> â€” ones that can be studied, debugged, and potentially aligned more deeply with human values.</p>

<hr />

<h2 id="final-thoughts">Final Thoughts</h2>

<p>Thereâ€™s something quietly radical about this line of research.</p>

<p>Not long ago, we believed language models were statistical parrots. Then we found circuits. Now we see thoughts. Itâ€™s a reminder that <strong>intelligence isnâ€™t magic â€” itâ€™s mechanics</strong>. And with the right tools, even the most complex digital minds can be understood.</p>

<p>Anthropicâ€™s new work marks a step toward <em>transparent cognition</em> â€” not just knowing <em>what</em> a model says, but <em>why</em> it thinks it.</p>

<p>And once we understand thatâ€¦ maybe weâ€™re not so far from building models that can explain themselves â€” to us, and perhaps, even to each other.</p>

<hr />

<p><em>Want to see how a single thought spreads across 70 transformer layers? Explore Anthropicâ€™s full article here: <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">Tracing the Thoughts of a Language Model</a>.</em></p>

    </main>

    <footer class="site-footer">
      <div class="container">
        <p>Â© 2025 Rahul Thakur â€¢ Powered by Jekyll</p>
      </div>
    </footer>
  </body>
</html>
